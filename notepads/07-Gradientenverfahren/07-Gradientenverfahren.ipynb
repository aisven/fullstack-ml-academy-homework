{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe zum Gradientenverfahren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this code block we gather all imports\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_pre=[0.65889035 0.82501181 0.64683985 0.85451935]\n",
      "w_pre_min=0.6468398464798055\n",
      "w_pre_max=0.8545193477457476\n",
      "w_pre_range=0.20767950126594203\n",
      "w_pre_range_reciprocal=4.815111717354615\n",
      "w_pre_min_repeated=[0.64683985 0.64683985 0.64683985 0.64683985]\n",
      "w_pre_minus_min=[0.0120505  0.17817197 0.         0.2076795 ]\n",
      "w_pre_min_max_normalized=[0.0580245  0.85791792 0.         1.        ]\n",
      "w_pre_masked=[0.058024502208169584 0.8579179223170673 -- --]\n",
      "w_init=[0.0580245  0.85791792]\n"
     ]
    }
   ],
   "source": [
    "# in this code block weight values are initialized in a very explicit verbose fashion\n",
    "\n",
    "# this is the number of weights in our model function\n",
    "# so it is also going to be the number of values in our vector of weights w\n",
    "number_of_weights = 2\n",
    "\n",
    "# in the following the variables prefixed with w_pre_ are just intermediate variables\n",
    "# the variable w_init is our vector of weights with their initial values\n",
    "\n",
    "# we draw random values based on a normal distribution\n",
    "# we actually draw two more than number_of_weights\n",
    "# since during the following min-max-normalization\n",
    "# the smallest value, the min, always becomes .0 (or at least very close to it owed to floats)\n",
    "# and the largest value, the max, always becomes 1. (or at least very close to it owed to floats)\n",
    "w_pre_number_of_values = number_of_weights + 2\n",
    "w_pre_random_values = np.random.normal(loc=.5, scale=.2, size=w_pre_number_of_values)\n",
    "print(f\"w_pre={w_pre_random_values}\")\n",
    "\n",
    "# the values in w_pre_initialized can be below 0 and above 1 so we min-max-normalize them\n",
    "# just out of curiosity through an explicit inline computation based on numpy primitives\n",
    "# formula is value_min_max_normalized = value - min / max - min\n",
    "\n",
    "# the min of the drawn random values and note that scalars have shape ()\n",
    "w_pre_min = w_pre_random_values.min()\n",
    "assert w_pre_min.shape == ()\n",
    "print(f\"w_pre_min={w_pre_min}\")\n",
    "\n",
    "# the max of the drawn random values\n",
    "w_pre_max = w_pre_random_values.max()\n",
    "assert w_pre_max.shape == ()\n",
    "print(f\"w_pre_max={w_pre_max}\")\n",
    "\n",
    "# the range\n",
    "w_pre_range = w_pre_max - w_pre_min\n",
    "assert w_pre_range.shape == ()\n",
    "print(f\"w_pre_range={w_pre_range}\")\n",
    "\n",
    "# 1 over the range\n",
    "w_pre_range_reciprocal = 1 / w_pre_range\n",
    "assert w_pre_range_reciprocal.shape == ()\n",
    "print(f\"w_pre_range_reciprocal={w_pre_range_reciprocal}\")\n",
    "\n",
    "# an array of the same shape as w_pre_random_values and where all values equal w_pre_min\n",
    "w_pre_min_repeated = np.full_like(w_pre_random_values, w_pre_min)\n",
    "assert w_pre_min_repeated.shape == (w_pre_number_of_values,)\n",
    "print(f\"w_pre_min_repeated={w_pre_min_repeated}\")\n",
    "\n",
    "# an array with all the random values after subtracting w_pre_min from them\n",
    "w_pre_minus_min = np.subtract(w_pre_random_values, w_pre_min_repeated)\n",
    "assert w_pre_minus_min.shape == (w_pre_number_of_values,)\n",
    "print(f\"w_pre_minus_min={w_pre_minus_min}\")\n",
    "\n",
    "# the array with the min-max-normalized random values\n",
    "w_pre_min_max_normalized = w_pre_minus_min * w_pre_range_reciprocal\n",
    "assert w_pre_min_max_normalized.shape == (w_pre_number_of_values,)\n",
    "print(f\"w_pre_min_max_normalized={w_pre_min_max_normalized}\")\n",
    "\n",
    "# we now mask the values that are equal or close to the minimum .0 or the maximum .1\n",
    "w_pre_masked = np.ma.masked_outside(w_pre_min_max_normalized, .001, .999, copy=True)\n",
    "assert w_pre_masked.shape == (w_pre_number_of_values,)\n",
    "print(f\"w_pre_masked={w_pre_masked}\")\n",
    "\n",
    "# to finally drop them using the function compressed() of the masking facility to obtain our weights\n",
    "w_init = w_pre_masked.compressed()\n",
    "print(f\"w_init={w_init}\")\n",
    "assert w_init.shape == (number_of_weights,)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad23019639f4f0cec1969a685ba2a43be98d322ffbcf7e3409a6239a86c6a8ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
